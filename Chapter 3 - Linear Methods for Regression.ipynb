{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression model assumes that the regression function $\\operatorname{E}(Y \\mid X)$ is linear in the inputs $X_1, ..., X_p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Linear Regression Models and Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As introduced in Chapter 2, we have an input vector $X^T = (X_1, X_2, ..., X_p)$, and we want to predict a real-valued output $Y$. The linear regression model has the form\n",
    "\n",
    "$$f(X) = \\beta_0 + \\sum_{j=1}^{p}X_j \\beta_j$$\n",
    "\n",
    "The linear model either assumes that the regression function $\\operatorname{E}(Y \\mid X)$ is linear, or that the linear model is a reasonable approximation. Here the varaibles $X_j$ can come from different sources:\n",
    "- quantitative inputs\n",
    "- transformations of quantitative inputs, such as log, square-root, or square\n",
    "- basis expansions, such as $X_2 = X_1^2$, $X_3 = X_1^3$, leading to a polynomial representation\n",
    "- numeric or \"dummy\" coding of the levels of qualitative inputs. For example, if $G$ is a five-level factor input, we might create $X_j$, $j = 1, 2, ..., 5$, such that $X_j = I(G = j)$. Together with this group of $X_j$ represents the effect of $G$ by a set of level-dependent constants, since in $\\sum_{j=1}^5 X_j\\beta_j$, one of the $X_j$'s is one, and the others are zero.\n",
    "- interactions between variables, for example, $X_3 = X_1 \\cdot X_2$\n",
    "\n",
    "No matter the source of the $X_j$, the model is linear in the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular estimation method is least squares, in which we pick the coefficients $\\beta = (\\beta_0, \\beta_1, ..., \\beta_p)^T$ to minimize the residual sum of squares\n",
    "\n",
    "$$\\begin{align*}\\operatorname{RSS}(\\beta) & = \\sum_{i=1}^{N} (y_i - f(x_i))^2\\\\\n",
    "& = \\sum_{i=1}^{N} \\left(y_i - \\beta_0 - \\sum_{j=1}^p x_{ij}\\beta_j\\right)^2\\end{align*}$$\n",
    "\n",
    "From a statistical point of view, this criterion is reasonable if the training observations $(x_i, y_i)$ represent independent random draws from their population. Note that the criterion makes no assumptions about the validity of model; it simply finds the best linear fit to the data. Least squares fitting is intuitively satisfying no matter how the data arise; the criterion measures the average lack of fit.\n",
    "\n",
    "How do we minimize the $\\operatorname{RSS}$? Denote by $\\mathbf{X}$ the $N \\times (p + 1)$ matrix with each row in an input vector (with a $1$ in the first position), and similarly let $\\mathbf{y}$ be the $N$-vector of outputs in the training set. Then we can write the residual sum-of-squares as\n",
    "\n",
    "$$\\operatorname{RSS} = (\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta)$$\n",
    "\n",
    "Differentiating w.r.t. $\\beta$ we obtain\n",
    "\n",
    "$$\\begin{align*} \\frac{\\partial \\operatorname{RSS}}{\\partial \\beta} & = -2 \\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\beta)\\\\\n",
    "\\frac{\\partial^2\\operatorname{RSS}}{\\partial\\beta\\partial\\beta^T} & = 2\\mathbf{X}^T\\mathbf{X} \\end{align*}$$\n",
    "\n",
    "Assuming (for the moment) that $\\mathbf{X}$ has full column rank, and hence $\\mathbf{X}^T\\mathbf{X}$ is positive definite, we set the first derivative to zero\n",
    "\n",
    "$$\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\beta) = 0$$\n",
    "\n",
    "to obtain the unique solution\n",
    "\n",
    "$$\\hat{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
