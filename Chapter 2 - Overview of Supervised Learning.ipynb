{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Variable Types and Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming convention for the prediction tasks:\n",
    "- **regression** when we predict quantitative outputs\n",
    "- **classification** when we predict qualitative outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Two Simple Approaches to Prediction: Least Squares and Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Linear Models and Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector of inputs $X^T = (X_1, X_2, ..., X_p)$, we predict the output $Y$ via the model\n",
    "\n",
    "$$\\hat{Y} = \\hat{\\beta_0} + \\sum_{j=1}^{p}X_j \\hat{\\beta_j}$$\n",
    "\n",
    "The term $\\hat{\\beta_0}$ is the intercept, also known as the **bias**. Often it is convenient to include the constant variable $1$ in $X$, include $\\hat{\\beta_0}$ in the vector $\\hat{\\beta}$, and then write the linear model in vector form as an inner product\n",
    "\n",
    "$$\\hat{Y} = X^T\\hat{\\beta}$$\n",
    "\n",
    "The most popular method to fit the linear model to the set of training data is the method of **least squares**. In this approach, we pick the coefficients $\\beta$ to minimize the residual sum of squares\n",
    "\n",
    "$$\\operatorname{RSS}(\\beta) = \\sum_{i=1}^{N} (y_i - x_i^T\\beta)^2$$\n",
    "\n",
    "The solution is easiest to characterize in matrix notation. We can write\n",
    "\n",
    "$$\\operatorname{RSS}(\\beta) = (\\mathbf{y} - \\mathbf{X}\\beta)^T(\\mathbf{y} - \\mathbf{X}\\beta)$$\n",
    "\n",
    "Differentiating w.r.t. $\\beta$ we get the **normal equations**\n",
    "\n",
    "$$\\mathbf{X}^T(\\mathbf{y} - \\mathbf{X}\\beta) = 0$$\n",
    "\n",
    "If $\\mathbf{X}^T\\mathbf{X}$ is nonsingular, then the unique solution is given by\n",
    "\n",
    "$$\\hat{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "Intuitively, it seems that we do not need a very large data set to fit such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import c2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_x, data_y = c2.generate_data(sample_size=100)\n",
    "sample_blue = data_x[data_y == 0, :]\n",
    "sample_orange = data_x[data_y == 1, :]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_subplot(221)\n",
    "ax.plot(sample_blue[:, 0], sample_blue[:, 1], 'o')\n",
    "ax.plot(sample_orange[:, 0], sample_orange[:, 1], 'o', color='orange')\n",
    "ax.set_title('0/1 Response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the linear model is fit on the data, there are several misclassifications on both side of the decision boundary. Consider the two possible scenarios:\n",
    "- **Scenario 1**: The training data in each class was generated from bivariate Gaussian distributions with uncorrelated components and different menas.\n",
    "- **Scenario 2**: The training data in each class came from a mixture of 10 low-variance Gaussian distributions, with individual means themselves distributed as Gaussian.\n",
    "\n",
    "In the case of one Gaussian per class, we will see in Chapter 4 that a linear decision boundary is the best one can do, and that our estimate is almost optimal. In the case of mixtures of tightly clustered Gaussian, a linear decision boundary is unlikely to be optimal, and in fact is not. The optimal decision boundary is nonlinear and disjoint, and as such will be much more difficult to obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Nearest-Neighbor Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest-neighbor methods use those obervations in the training set $\\mathcal{T}$ closest in input space to $x$ to form $\\hat{Y}$. Specifically, the $k$-nearest neighbor fit for $\\hat{Y}$ is defined as\n",
    "\n",
    "$$\\hat{Y}(x) = \\frac{1}{k} \\sum_{x_i \\in N_k(x)} y_i$$\n",
    "\n",
    "where $N_k(x)$ is the neighborhood of $x$ defined by the $k$ closest points $x_i$ in the training sample.\n",
    "\n",
    "When $k = 1$, it is an 1-nearest-neighbor classification: $\\hat{Y}$ is assigned the value $y_l$ of the closest point $x_l$ to $x$ in the training data. In this case, the regions of classification can be computed relatively easily, and correspond to a **Voronoi tesselation** of the training data, where each point $x_i$ has an associated tile bounding the region for which it is the closest input point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that far fewer training observations are misclassified when using k-nearest-neighbor instead of least squares. This should not give too much comfort, since none of training data are misclassified when using 1-nearest-neighbor. A little thought suggests that for k-nearest-neighbor fits, the error on the training data should be approximately an increasing function of $k$, and will always be $0$ for $k = 1$.\n",
    "\n",
    "It appears that k-nearest-neighbor fits have a single parameter, $k$, compared to the $p$ parameters in least-squares fits. Although this is the case, we will see that the **effective** number of parameters of k-nearest-neighbors is $N/k$ and is generally bigger than $p$. Note that if the neighborhoods were nonoverlapping, there would be $N/k$ neighborhoods and we would fit one parameter (a mean) in each neighborhood.\n",
    "\n",
    "It is also clear that we cannot use sum-of-squared errors on the training set as a criterion for picking $k$, since we would always pick $k = 1$! It would seem that k-nearest-neighbor methods would be more appropriate for the mixture Scenario 2, while for Gaussian data, the decision boundaries of k-nearest-neighbor would be unnecessarily noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 From Least Squares to Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Least squares: low variance and potentially high bias\n",
    "- k-nearest-neighbor: high variance and low bias\n",
    "\n",
    "Each method has its own situations for which it works best; linear regression is more appropriate for Scenario 1, while nearest neighbor are more suitable for Scenario 2.\n",
    "\n",
    "The data in fact were simulated from a model somewhere between the two, but closer to Scenario 2. First we generated 10 means $m_k$ from a bivariate Gaussian distribution $N((1, 0)^T, \\mathbf{I})$ and labeled this class blue. Similarly, 10 more were drawn from $N((0, 1)^T, \\mathbf{I})$ and labeled class orange. Then for each class we generated 100 observations as follows: for each observation, we picked an $m_k$ at random with probability $1/10$, and then generated a $N(m_k, \\mathbf{I}/5)$, thus leading to a mixture of Gaussian clusters for each class.\n",
    "\n",
    "A large subset of the most popular techniques in use today are variants of these two simple procedures. In fact, 1-nearest-neighbor, the simplest of all, captures a large percentage of the market for low-dimensional problems. The following list describes some ways in which these simple procedures have been enhanced:\n",
    "- Kernel methods use weights that decrease smoothly to zero with distance from the target point, rather than the effective 0/1 weights used by k-nearest neighbors.\n",
    "- In high-dimensional spaces the distance kernels are modified to emphasize some variable more than others.\n",
    "- Local regression its linear models by locally weighted least squares, rather than fitting constants locally.\n",
    "- Linear models fit to a basis expansion of the original inputs allow arbitrarily complex models.\n",
    "- Projection pursuit and nueral network models consist of sums of non-linearly transformed linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Statistical Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first consider the case of a quantitative output, and place ourselves in the world of random variables and probability spaces. Let $X \\in \\mathbb{R}^p$ denote a real valued random input vector, and $Y \\in \\mathbb{R}$ a real valued random output variable, with joint distribution $\\operatorname{Pr}(X, Y)$. We seek a function $f(X)$ for predicting $Y$ given values of the input $X$. This theory requires a **loss function** $L(Y, f(X))$ for penalizing errors in prediction, and by far the most common and convenient is **squared error loss**: $L(Y, f(X)) = (Y - f(X))^2$. This leads to a criterion for choosing $f$:\n",
    "\n",
    "$$\\begin{align*}\\operatorname{EPE}(f) & = \\operatorname{E}(Y - f(X))^2\\\\\n",
    "& = \\int \\left[y - f(x)\\right]^2\\operatorname{Pr}(dx, dy)\\end{align*}$$\n",
    "\n",
    "the expected (squared) prediction error. By conditioning on $X$, we can write $\\operatorname{EPE}$ as\n",
    "\n",
    "$$\\operatorname{EPE}(f) = \\operatorname{E}_X\\operatorname{E}_{Y \\mid X} \\left(\\left[Y - f\\left(X\\right)\\right]^2 \\mid X\\right)$$\n",
    "\n",
    "and we see that it suffices to minimize $\\operatorname{EPE}$ pointwise:\n",
    "\n",
    "$$f(x) = \\operatorname{argmin}_c\\operatorname{E}_{Y \\mid X} \\left(\\left[Y - c\\right]^2 \\mid X = x\\right)$$\n",
    "\n",
    "The solution is\n",
    "\n",
    "$$f(x) = \\operatorname{E}(Y \\mid X = x)$$\n",
    "\n",
    "the conditional expectation, also known as the **regression function**. Thus the best prediction of $Y$ at any point $X = x$ is the conditional mean, when best is measured by average squared error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
